# 线性模型

## 1.线性回归模型

### 1.1 模型设计

    1.实现了对数据的归一化

    由于 sklearn自带的波士顿房价数据集的各个维度的特征的数值范围差异较大,
    导致模型训练时会发生 loss 和 gradient 的上溢出现象, 因此对各个特征进行均值和方差的归一化

    另外, 标签y 和 特征X 的差距较大, 我们发现线性回归模型不收敛, 解决方案:

     M1.可以对 y 进行归一化
     M2.在 h(x) 中加入偏置项 b, 一般线性回归都要考虑偏置项

    2.学习算法: 实现了带正则化的梯度下降 和 解析法直接求解模型的参数

### 1.2 实验结果

    1. 不加入正则化 max_iter=50, learning_rate=0.1

        epcho: 0 , loss:295.76924175824155
        ...
        epcho: 49 , loss:11.68898429599343

        W: [-0.6352397   0.54656253 -0.33105276  0.63386307 -1.08895726  3.09167393
             -0.18907642 -2.18630367  1.0257064  -0.64927669 -1.91210443  0.85438756
             -3.45453258]

        by sklearn , the squared_error: 16.61168620800721
        by xrh , the squared_error: 16.21430292366462

    2. 加入L2正则化 reg_lambda=0.5,  max_iter=50, learning_rate=0.1

        epcho: 0 , loss:295.76924175824155
        ...
        epcho: 35 , loss:17.995616868685445
        ...
        epcho: 49 , loss:17.839313624370263

        W: [-0.54515783  0.41398274 -0.45347702  0.59311115 -0.59120612  2.44687475
             -0.23729531 -0.98859324  0.22114531 -0.51307395 -1.42225501  0.64833666
             -2.37634278]

        by xrh , the squared_error: 20.93320421835776

        我们发现在训练时损失在中间的 epcho就不再下降, 说明模型训练并没有出现过拟合, 反而是欠拟合的，
        为了提高在测试集上的表现, 可以调低 L2正则化 的强度

    3. 加入L2正则化 reg_lambda=0.1,  max_iter=50, learning_rate=0.1

       by xrh , the squared_error: 16.90898232586299


    4. 加入L1正则化 reg_alpha=0.5,  max_iter=50, learning_rate=0.1

       epcho: 0 , loss:295.76924175824155
       ...
       epcho: 28 , loss:18.92783812210059
       ...
       epcho: 49 , loss:18.14832577632172

       W: [-1.33345811e-01  7.00199249e-02 -3.48548579e-03  2.76635968e-01
             -1.16584281e-01  3.05385413e+00  3.11102299e-02 -3.12883736e-01
             -2.84816726e-03 -7.50169381e-02 -1.62881873e+00  4.95837410e-01
             -3.40253866e+00]

       by xrh , the squared_error: 20.34544600809011

       观察到特征的权重 W 中出现很小的值, 说明L1 正则化导致了特征选择的作用

    5. 对 y 归一化, 采用解析式直接求解

        by sklearn , the squared_error: 0.19677533221422852
        by xrh , the squared_error: 0.4146028764452961